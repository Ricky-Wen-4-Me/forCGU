{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38311414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97cfe584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y) : \n",
    "    # [0 ~ 255] => [-1 ~ 1]\n",
    "    x = 2 * tf.cast(x, dtype = tf.float32) / 255. - 1.\n",
    "    y = tf.cast(y, dtype = tf.int32)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c97efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset :  (50000, 32, 32, 3) (50000, 10) 0 255\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# [50k, 32, 32, 3], [10k, 1]\n",
    "(x, y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "y = tf.squeeze(y)\n",
    "y_test = tf.squeeze(y_test)\n",
    "\n",
    "y = tf.one_hot(y, depth = 10) # [50k, 10]\n",
    "y_test = tf.one_hot(y_test, depth = 10) # [10k, 10]\n",
    "\n",
    "print('dataset : ', x.shape, y.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b7bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_db = train_db.map(preprocess).shuffle(10000).batch(batch_size)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_db = test_db.map(preprocess).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df1be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3) (128, 10)\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_db))\n",
    "\n",
    "print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440eef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(layers.Layer) :\n",
    "    # to replace standard layers.Dense()\n",
    "    def __init__(self, in_dim, out_dim) :\n",
    "        super(MyDense, self).__init__()\n",
    "        \n",
    "        self.kernel = self.add_variable('W', [in_dim, out_dim])\n",
    "        # self.bias = self.add_variable('b', [out_dim])\n",
    "        \n",
    "    def call(self, inputs, tarining = None) :\n",
    "        \n",
    "        out = inputs @ self.kernel # + self.bias\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e384e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(keras.Model) :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super(MyNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = MyDense(32*32*3, 1028)\n",
    "        self.fc2 = MyDense(1028, 512)\n",
    "        self.fc3 = MyDense(512, 256)\n",
    "        self.fc4 = MyDense(256, 128)\n",
    "        self.fc5 = MyDense(128, 64)\n",
    "        self.fc6 = MyDense(64, 32)\n",
    "        self.fc7 = MyDense(32, 16)\n",
    "        self.fc8 = MyDense(16, 10)\n",
    "        \n",
    "    def call(self, inputs, tarining = None) : \n",
    "        \"\"\"\n",
    "        parameters => inputs : [b, 32, 32, 3]\n",
    "        parameters => training : \n",
    "        return : \n",
    "        \"\"\"\n",
    "        x = tf.reshape(inputs, [-1, 32*32*3])\n",
    "        # [b, 32*32*3] => [b, 256]\n",
    "        x = tf.nn.relu(self.fc1(x))\n",
    "        # [b, 256] => [b, 128]\n",
    "        x = tf.nn.relu(self.fc2(x))\n",
    "        x = tf.nn.relu(self.fc3(x))\n",
    "        x = tf.nn.relu(self.fc4(x))\n",
    "        x = tf.nn.relu(self.fc5(x))\n",
    "        x = tf.nn.relu(self.fc6(x))\n",
    "        x = tf.nn.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595385ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\MyFirstTensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650b9e10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "391/391 [==============================] - 7s 8ms/step - loss: 1.8287 - accuracy: 0.3544\n",
      "Epoch 2/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.5464 - accuracy: 0.4563 - val_loss: 1.5151 - val_accuracy: 0.4672\n",
      "Epoch 3/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.4236 - accuracy: 0.5003\n",
      "Epoch 4/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.3254 - accuracy: 0.5367 - val_loss: 1.3983 - val_accuracy: 0.5134\n",
      "Epoch 5/15\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.2368 - accuracy: 0.5659\n",
      "Epoch 6/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1550 - accuracy: 0.5942 - val_loss: 1.4164 - val_accuracy: 0.5232\n",
      "Epoch 7/15\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1.0750 - accuracy: 0.6198\n",
      "Epoch 8/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9995 - accuracy: 0.6490 - val_loss: 1.4127 - val_accuracy: 0.5415\n",
      "Epoch 9/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9150 - accuracy: 0.6773\n",
      "Epoch 10/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8464 - accuracy: 0.7036 - val_loss: 1.5341 - val_accuracy: 0.5411\n",
      "Epoch 11/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.7726 - accuracy: 0.7266\n",
      "Epoch 12/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7095 - accuracy: 0.7500 - val_loss: 1.7714 - val_accuracy: 0.5398\n",
      "Epoch 13/15\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6446 - accuracy: 0.7703\n",
      "Epoch 14/15\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5876 - accuracy: 0.7921 - val_loss: 1.8683 - val_accuracy: 0.5385\n",
      "Epoch 15/15\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.5452 - accuracy: 0.8063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d4ecfa460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from_logits = True : https://www.cnblogs.com/harrysong666/p/14635131.html\n",
    "network.compile(optimizer = optimizers.Adam(learning_rate = 1e-3),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits = True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "network.fit(train_db, epochs = 15, validation_data = test_db, validation_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfd92db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9411 - accuracy: 0.5378\n",
      "saved to mySaveWeight/weights.ckpt\n"
     ]
    }
   ],
   "source": [
    "network.evaluate(test_db)\n",
    "\n",
    "network.save_weights('mySaveWeight/weights.ckpt')\n",
    "del network\n",
    "\n",
    "print('saved to mySaveWeight/weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "027689f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights from mySaveWeight/weights.ckpt\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9411 - accuracy: 0.5378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9411288499832153, 0.5378000140190125]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded weights\n",
    "network = MyNetwork()\n",
    "\n",
    "network.compile(optimizer = optimizers.Adam(learning_rate = 1e-3),\n",
    "               loss = tf.losses.CategoricalCrossentropy(from_logits = True),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "network.load_weights('mySaveWeight/weights.ckpt')\n",
    "\n",
    "print('loaded weights from mySaveWeight/weights.ckpt')\n",
    "\n",
    "network.evaluate(test_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489fd3f8",
   "metadata": {},
   "source": [
    "# Reference\n",
    "# 网易云课堂《深度学习与TensorFlow 2入门实战》\n",
    "https://www.youtube.com/playlist?list=PLh7DRwYmUgh7swOvZUZ52LMeGDmjFH0nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9320b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
